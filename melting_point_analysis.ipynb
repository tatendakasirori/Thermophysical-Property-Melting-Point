{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting Point Prediction with Molecular Descriptors\n",
    "\n",
    "This notebook generates molecular descriptors using RDKit and Mordred, creates visualizations, and trains XGBoost/LightGBM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Lipinski, rdMolDescriptors\n",
    "from mordred import Calculator, descriptors\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nTarget (Tm) statistics:\")\n",
    "print(train_df['Tm'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Molecular Descriptors\n",
    "\n",
    "We'll create descriptors that are closely tied to melting point:\n",
    "- **Molecular Weight**: Larger molecules tend to have higher melting points\n",
    "- **LogP**: Lipophilicity affects crystal packing\n",
    "- **TPSA**: Polar surface area relates to intermolecular forces\n",
    "- **H-bond donors/acceptors**: Hydrogen bonding increases melting point\n",
    "- **Rotatable bonds**: Molecular flexibility (lower = higher Tm)\n",
    "- **Aromatic rings**: Pi-stacking increases melting point\n",
    "- **Fraction sp3**: Molecular shape affects packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rdkit_descriptors(smiles_list):\n",
    "    \"\"\"Compute RDKit descriptors related to melting point\"\"\"\n",
    "    descriptors_list = []\n",
    "    \n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            descriptors_list.append({key: np.nan for key in [\n",
    "                'MolWt', 'LogP', 'TPSA', 'NumHDonors', 'NumHAcceptors',\n",
    "                'NumRotatableBonds', 'NumAromaticRings', 'NumHeavyAtoms',\n",
    "                'FractionCSP3', 'NumRings', 'NumHeteroatoms', 'MolMR',\n",
    "                'NumValenceElectrons', 'NumRadicalElectrons', 'HallKierAlpha',\n",
    "                'NumAliphaticRings', 'NumSaturatedRings', 'NumAromaticHeterocycles',\n",
    "                'NumAliphaticHeterocycles', 'NumSaturatedHeterocycles'\n",
    "            ]})\n",
    "            continue\n",
    "            \n",
    "        desc = {\n",
    "            'MolWt': Descriptors.MolWt(mol),\n",
    "            'LogP': Descriptors.MolLogP(mol),\n",
    "            'TPSA': Descriptors.TPSA(mol),\n",
    "            'NumHDonors': Lipinski.NumHDonors(mol),\n",
    "            'NumHAcceptors': Lipinski.NumHAcceptors(mol),\n",
    "            'NumRotatableBonds': Lipinski.NumRotatableBonds(mol),\n",
    "            'NumAromaticRings': rdMolDescriptors.CalcNumAromaticRings(mol),\n",
    "            'NumHeavyAtoms': Lipinski.HeavyAtomCount(mol),\n",
    "            'FractionCSP3': rdMolDescriptors.CalcFractionCSP3(mol),\n",
    "            'NumRings': rdMolDescriptors.CalcNumRings(mol),\n",
    "            'NumHeteroatoms': rdMolDescriptors.CalcNumHeteroatoms(mol),\n",
    "            'MolMR': Descriptors.MolMR(mol),  # Molar refractivity\n",
    "            'NumValenceElectrons': Descriptors.NumValenceElectrons(mol),\n",
    "            'NumRadicalElectrons': Descriptors.NumRadicalElectrons(mol),\n",
    "            'HallKierAlpha': Descriptors.HallKierAlpha(mol),\n",
    "            'NumAliphaticRings': rdMolDescriptors.CalcNumAliphaticRings(mol),\n",
    "            'NumSaturatedRings': rdMolDescriptors.CalcNumSaturatedRings(mol),\n",
    "            'NumAromaticHeterocycles': rdMolDescriptors.CalcNumAromaticHeterocycles(mol),\n",
    "            'NumAliphaticHeterocycles': rdMolDescriptors.CalcNumAliphaticHeterocycles(mol),\n",
    "            'NumSaturatedHeterocycles': rdMolDescriptors.CalcNumSaturatedHeterocycles(mol),\n",
    "        }\n",
    "        descriptors_list.append(desc)\n",
    "    \n",
    "    return pd.DataFrame(descriptors_list)\n",
    "\n",
    "print(\"Computing RDKit descriptors for training data...\")\n",
    "train_rdkit = compute_rdkit_descriptors(train_df['SMILES'].values)\n",
    "print(\"Computing RDKit descriptors for test data...\")\n",
    "test_rdkit = compute_rdkit_descriptors(test_df['SMILES'].values)\n",
    "\n",
    "print(f\"\\nRDKit descriptors generated: {train_rdkit.shape[1]}\")\n",
    "print(train_rdkit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mordred_descriptors(smiles_list):\n",
    "    \"\"\"Compute Mordred descriptors that work for all molecules\"\"\"\n",
    "    # Create molecules\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
    "    \n",
    "    # Use only 2D descriptors (no 3D) to ensure universal applicability\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    \n",
    "    print(f\"Calculating {len(calc.descriptors)} Mordred descriptors...\")\n",
    "    df = calc.pandas(mols)\n",
    "    \n",
    "    # Convert to numeric and filter out columns with any errors/NaN\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Keep only columns with no NaN values\n",
    "    valid_cols = df.columns[df.notna().all()].tolist()\n",
    "    df_clean = df[valid_cols]\n",
    "    \n",
    "    # Remove columns with zero variance\n",
    "    df_clean = df_clean.loc[:, df_clean.std() > 0]\n",
    "    \n",
    "    print(f\"Valid Mordred descriptors (no NaN, non-zero variance): {df_clean.shape[1]}\")\n",
    "    return df_clean\n",
    "\n",
    "print(\"Computing Mordred descriptors for training data...\")\n",
    "train_mordred = compute_mordred_descriptors(train_df['SMILES'].values)\n",
    "print(\"\\nComputing Mordred descriptors for test data...\")\n",
    "test_mordred = compute_mordred_descriptors(test_df['SMILES'].values)\n",
    "\n",
    "# Ensure both have the same columns\n",
    "common_mordred_cols = list(set(train_mordred.columns) & set(test_mordred.columns))\n",
    "train_mordred = train_mordred[common_mordred_cols]\n",
    "test_mordred = test_mordred[common_mordred_cols]\n",
    "\n",
    "print(f\"\\nFinal Mordred descriptors: {len(common_mordred_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original group features\n",
    "group_cols = [col for col in train_df.columns if col.startswith('Group')]\n",
    "train_groups = train_df[group_cols]\n",
    "test_groups = test_df[group_cols]\n",
    "\n",
    "# Combine all features\n",
    "X_train_full = pd.concat([\n",
    "    train_groups.reset_index(drop=True),\n",
    "    train_rdkit.reset_index(drop=True),\n",
    "    train_mordred.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "X_test_full = pd.concat([\n",
    "    test_groups.reset_index(drop=True),\n",
    "    test_rdkit.reset_index(drop=True),\n",
    "    test_mordred.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "y_train = train_df['Tm']\n",
    "\n",
    "print(f\"Original group features: {len(group_cols)}\")\n",
    "print(f\"RDKit descriptors: {train_rdkit.shape[1]}\")\n",
    "print(f\"Mordred descriptors: {train_mordred.shape[1]}\")\n",
    "print(f\"Total features: {X_train_full.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Distribution of Melting Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(train_df['Tm'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(train_df['Tm'].mean(), color='red', linestyle='--', linewidth=2, label=f\"Mean: {train_df['Tm'].mean():.1f} K\")\n",
    "axes[0].axvline(train_df['Tm'].median(), color='orange', linestyle='--', linewidth=2, label=f\"Median: {train_df['Tm'].median():.1f} K\")\n",
    "axes[0].set_xlabel('Melting Point (K)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Melting Points', fontsize=14)\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(train_df['Tm'], vert=True)\n",
    "axes[1].set_ylabel('Melting Point (K)', fontsize=12)\n",
    "axes[1].set_title('Melting Point Box Plot', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz_1_melting_point_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: viz_1_melting_point_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Correlation Matrix of Key Descriptors with Melting Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key RDKit descriptors for correlation analysis\n",
    "key_descriptors = ['MolWt', 'LogP', 'TPSA', 'NumHDonors', 'NumHAcceptors', \n",
    "                   'NumRotatableBonds', 'NumAromaticRings', 'NumHeavyAtoms',\n",
    "                   'FractionCSP3', 'NumRings', 'NumHeteroatoms', 'MolMR']\n",
    "\n",
    "# Create correlation dataframe\n",
    "corr_df = train_rdkit[key_descriptors].copy()\n",
    "corr_df['Tm'] = train_df['Tm'].values\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = corr_df.corr()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "            center=0, square=True, linewidths=0.5, ax=ax,\n",
    "            cbar_kws={'label': 'Correlation Coefficient'})\n",
    "ax.set_title('Correlation Matrix: Key Molecular Descriptors vs Melting Point', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz_2_correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: viz_2_correlation_matrix.png\")\n",
    "\n",
    "# Print correlations with Tm\n",
    "print(\"\\nCorrelations with Melting Point (Tm):\")\n",
    "tm_corr = corr_matrix['Tm'].drop('Tm').sort_values(key=abs, ascending=False)\n",
    "print(tm_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Scatter Plots of Top Correlated Descriptors vs Melting Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 4 descriptors by absolute correlation with Tm\n",
    "top_descriptors = tm_corr.head(4).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, desc in enumerate(top_descriptors):\n",
    "    ax = axes[i]\n",
    "    corr_val = tm_corr[desc]\n",
    "    \n",
    "    ax.scatter(train_rdkit[desc], train_df['Tm'], alpha=0.4, s=20, c='steelblue')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(train_rdkit[desc].dropna(), train_df['Tm'].loc[train_rdkit[desc].notna()], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(train_rdkit[desc].min(), train_rdkit[desc].max(), 100)\n",
    "    ax.plot(x_line, p(x_line), 'r--', linewidth=2, label=f'r = {corr_val:.3f}')\n",
    "    \n",
    "    ax.set_xlabel(desc, fontsize=12)\n",
    "    ax.set_ylabel('Melting Point (K)', fontsize=12)\n",
    "    ax.set_title(f'{desc} vs Melting Point', fontsize=13)\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz_3_scatter_top_descriptors.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: viz_3_scatter_top_descriptors.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Melting Point by Molecular Properties (Categorical Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Melting Point by Number of Aromatic Rings\n",
    "ax = axes[0, 0]\n",
    "ring_data = train_rdkit['NumAromaticRings'].copy()\n",
    "ring_data = ring_data.clip(upper=5)  # Group 5+ together\n",
    "ring_groups = pd.concat([ring_data, train_df['Tm']], axis=1)\n",
    "ring_groups.boxplot(column='Tm', by='NumAromaticRings', ax=ax)\n",
    "ax.set_xlabel('Number of Aromatic Rings', fontsize=12)\n",
    "ax.set_ylabel('Melting Point (K)', fontsize=12)\n",
    "ax.set_title('Melting Point by Aromatic Ring Count', fontsize=13)\n",
    "plt.suptitle('')\n",
    "\n",
    "# 2. Melting Point by H-bond Donors\n",
    "ax = axes[0, 1]\n",
    "hd_data = train_rdkit['NumHDonors'].copy()\n",
    "hd_data = hd_data.clip(upper=4)\n",
    "hd_groups = pd.concat([hd_data, train_df['Tm']], axis=1)\n",
    "hd_groups.boxplot(column='Tm', by='NumHDonors', ax=ax)\n",
    "ax.set_xlabel('Number of H-bond Donors', fontsize=12)\n",
    "ax.set_ylabel('Melting Point (K)', fontsize=12)\n",
    "ax.set_title('Melting Point by H-bond Donors', fontsize=13)\n",
    "plt.suptitle('')\n",
    "\n",
    "# 3. Melting Point by Molecular Weight bins\n",
    "ax = axes[1, 0]\n",
    "mw_bins = pd.cut(train_rdkit['MolWt'], bins=[0, 100, 200, 300, 400, 1000], \n",
    "                 labels=['<100', '100-200', '200-300', '300-400', '>400'])\n",
    "mw_groups = pd.DataFrame({'MolWt_bin': mw_bins, 'Tm': train_df['Tm']})\n",
    "mw_groups.boxplot(column='Tm', by='MolWt_bin', ax=ax)\n",
    "ax.set_xlabel('Molecular Weight Range', fontsize=12)\n",
    "ax.set_ylabel('Melting Point (K)', fontsize=12)\n",
    "ax.set_title('Melting Point by Molecular Weight', fontsize=13)\n",
    "plt.suptitle('')\n",
    "\n",
    "# 4. Melting Point by Total Rings\n",
    "ax = axes[1, 1]\n",
    "ring_total = train_rdkit['NumRings'].copy()\n",
    "ring_total = ring_total.clip(upper=5)\n",
    "ring_total_groups = pd.concat([ring_total, train_df['Tm']], axis=1)\n",
    "ring_total_groups.boxplot(column='Tm', by='NumRings', ax=ax)\n",
    "ax.set_xlabel('Total Number of Rings', fontsize=12)\n",
    "ax.set_ylabel('Melting Point (K)', fontsize=12)\n",
    "ax.set_title('Melting Point by Total Ring Count', fontsize=13)\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz_4_melting_point_by_properties.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: viz_4_melting_point_by_properties.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Feature Importance Heatmap (Top Mordred Descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations of Mordred descriptors with Tm\n",
    "mordred_corr = train_mordred.corrwith(train_df['Tm']).dropna()\n",
    "mordred_corr_sorted = mordred_corr.abs().sort_values(ascending=False)\n",
    "\n",
    "# Top 20 Mordred descriptors by correlation\n",
    "top_20_mordred = mordred_corr_sorted.head(20).index.tolist()\n",
    "top_20_corr = mordred_corr[top_20_mordred]\n",
    "\n",
    "# Create bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "colors = ['steelblue' if x > 0 else 'coral' for x in top_20_corr]\n",
    "bars = ax.barh(range(len(top_20_corr)), top_20_corr.values, color=colors)\n",
    "ax.set_yticks(range(len(top_20_corr)))\n",
    "ax.set_yticklabels(top_20_corr.index)\n",
    "ax.set_xlabel('Correlation with Melting Point', fontsize=12)\n",
    "ax.set_title('Top 20 Mordred Descriptors by Correlation with Tm', fontsize=14)\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add correlation values on bars\n",
    "for i, (bar, val) in enumerate(zip(bars, top_20_corr.values)):\n",
    "    ax.text(val + 0.01 if val > 0 else val - 0.01, i, f'{val:.3f}', \n",
    "            va='center', ha='left' if val > 0 else 'right', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz_5_top_mordred_correlations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: viz_5_top_mordred_correlations.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Models with Enhanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle any remaining NaN values\n",
    "X_train_clean = X_train_full.fillna(0)\n",
    "X_test_clean = X_test_full.fillna(0)\n",
    "\n",
    "# Remove infinite values\n",
    "X_train_clean = X_train_clean.replace([np.inf, -np.inf], 0)\n",
    "X_test_clean = X_test_clean.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(f\"Final training features: {X_train_clean.shape}\")\n",
    "print(f\"Final test features: {X_test_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def evaluate_model(model, X, y, model_name):\n",
    "    \"\"\"Evaluate model using 5-fold cross-validation\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Evaluating: {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    y_pred_cv = cross_val_predict(model, X, y, cv=kfold)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "    mae = mean_absolute_error(y, y_pred_cv)\n",
    "    r2 = r2_score(y, y_pred_cv)\n",
    "    \n",
    "    print(f\"\\nCross-Validation Results (5-Fold):\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model, {'RMSE': rmse, 'MAE': mae, 'R2': r2}, y_pred_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION WITH ENHANCED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "xgb_trained, xgb_metrics, xgb_cv_pred = evaluate_model(xgb_model, X_train_clean, y_train, \"XGBoost\")\n",
    "lgbm_trained, lgbm_metrics, lgbm_cv_pred = evaluate_model(lgbm_model, X_train_clean, y_train, \"LightGBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'MAE', 'R²'],\n",
    "    'XGBoost': [xgb_metrics['RMSE'], xgb_metrics['MAE'], xgb_metrics['R2']],\n",
    "    'LightGBM': [lgbm_metrics['RMSE'], lgbm_metrics['MAE'], lgbm_metrics['R2']]\n",
    "})\n",
    "\n",
    "results_df['Best'] = results_df.apply(\n",
    "    lambda row: 'XGBoost' if (row['Metric'] == 'R²' and row['XGBoost'] > row['LightGBM']) or \n",
    "                            (row['Metric'] != 'R²' and row['XGBoost'] < row['LightGBM'])\n",
    "                else 'LightGBM', axis=1\n",
    ")\n",
    "\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "xgb_predictions = xgb_trained.predict(X_test_clean)\n",
    "lgbm_predictions = lgbm_trained.predict(X_test_clean)\n",
    "\n",
    "# Save predictions\n",
    "xgb_submission = pd.DataFrame({'id': test_df['id'], 'Tm': xgb_predictions})\n",
    "lgbm_submission = pd.DataFrame({'id': test_df['id'], 'Tm': lgbm_predictions})\n",
    "\n",
    "xgb_submission.to_csv('submission_xgboost_enhanced.csv', index=False)\n",
    "lgbm_submission.to_csv('submission_lightgbm_enhanced.csv', index=False)\n",
    "\n",
    "print(\"\\nPredictions saved:\")\n",
    "print(\"  - submission_xgboost_enhanced.csv\")\n",
    "print(\"  - submission_lightgbm_enhanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, pred, name, metrics in zip(axes, [xgb_cv_pred, lgbm_cv_pred], \n",
    "                                     ['XGBoost', 'LightGBM'],\n",
    "                                     [xgb_metrics, lgbm_metrics]):\n",
    "    ax.scatter(y_train, pred, alpha=0.4, s=20)\n",
    "    ax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', linewidth=2)\n",
    "    ax.set_xlabel('Actual Melting Point (K)', fontsize=12)\n",
    "    ax.set_ylabel('Predicted Melting Point (K)', fontsize=12)\n",
    "    ax.set_title(f'{name}: Actual vs Predicted\\nR² = {metrics[\"R2\"]:.4f}, RMSE = {metrics[\"RMSE\"]:.2f}', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz_6_actual_vs_predicted.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: viz_6_actual_vs_predicted.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from XGBoost\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_clean.columns,\n",
    "    'importance': xgb_trained.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Top 30 features\n",
    "top_30 = feature_importance.head(30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.barh(range(len(top_30)), top_30['importance'].values, color='steelblue')\n",
    "ax.set_yticks(range(len(top_30)))\n",
    "ax.set_yticklabels(top_30['feature'].values)\n",
    "ax.set_xlabel('Feature Importance', fontsize=12)\n",
    "ax.set_title('Top 30 Features by XGBoost Importance', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('viz_7_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: viz_7_feature_importance.png\")\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance.head(20).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
