{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting Point Prediction - Model Training\n",
    "\n",
    "This notebook trains XGBoost and LightGBM models using molecular descriptors from RDKit and Mordred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Lipinski, rdMolDescriptors\n",
    "from mordred import Calculator, descriptors\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2662\n",
      "Test samples: 666\n",
      "Original features (Group columns): 424\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Original features (Group columns): {len([c for c in train_df.columns if c.startswith('Group')])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Molecular Descriptors\n",
    "\n",
    "### 2.1 RDKit Descriptors\n",
    "Key descriptors related to melting point:\n",
    "- **MolWt**: Molecular weight\n",
    "- **LogP**: Lipophilicity\n",
    "- **TPSA**: Topological polar surface area\n",
    "- **NumHDonors/Acceptors**: Hydrogen bonding capacity\n",
    "- **NumAromaticRings**: Pi-stacking potential\n",
    "- **FractionCSP3**: Molecular flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing RDKit descriptors for training data...\n",
      "Computing RDKit descriptors for test data...\n",
      "\n",
      "RDKit descriptors: 20\n"
     ]
    }
   ],
   "source": [
    "def compute_rdkit_descriptors(smiles_list):\n",
    "    \"\"\"Compute RDKit descriptors\"\"\"\n",
    "    descriptors_list = []\n",
    "    \n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            descriptors_list.append({key: np.nan for key in [\n",
    "                'MolWt', 'LogP', 'TPSA', 'NumHDonors', 'NumHAcceptors',\n",
    "                'NumRotatableBonds', 'NumAromaticRings', 'NumHeavyAtoms',\n",
    "                'FractionCSP3', 'NumRings', 'NumHeteroatoms', 'MolMR',\n",
    "                'NumValenceElectrons', 'NumRadicalElectrons', 'HallKierAlpha',\n",
    "                'NumAliphaticRings', 'NumSaturatedRings', 'NumAromaticHeterocycles',\n",
    "                'NumAliphaticHeterocycles', 'NumSaturatedHeterocycles'\n",
    "            ]})\n",
    "            continue\n",
    "            \n",
    "        desc = {\n",
    "            'MolWt': Descriptors.MolWt(mol),\n",
    "            'LogP': Descriptors.MolLogP(mol),\n",
    "            'TPSA': Descriptors.TPSA(mol),\n",
    "            'NumHDonors': Lipinski.NumHDonors(mol),\n",
    "            'NumHAcceptors': Lipinski.NumHAcceptors(mol),\n",
    "            'NumRotatableBonds': Lipinski.NumRotatableBonds(mol),\n",
    "            'NumAromaticRings': rdMolDescriptors.CalcNumAromaticRings(mol),\n",
    "            'NumHeavyAtoms': Lipinski.HeavyAtomCount(mol),\n",
    "            'FractionCSP3': rdMolDescriptors.CalcFractionCSP3(mol),\n",
    "            'NumRings': rdMolDescriptors.CalcNumRings(mol),\n",
    "            'NumHeteroatoms': rdMolDescriptors.CalcNumHeteroatoms(mol),\n",
    "            'MolMR': Descriptors.MolMR(mol),\n",
    "            'NumValenceElectrons': Descriptors.NumValenceElectrons(mol),\n",
    "            'NumRadicalElectrons': Descriptors.NumRadicalElectrons(mol),\n",
    "            'HallKierAlpha': Descriptors.HallKierAlpha(mol),\n",
    "            'NumAliphaticRings': rdMolDescriptors.CalcNumAliphaticRings(mol),\n",
    "            'NumSaturatedRings': rdMolDescriptors.CalcNumSaturatedRings(mol),\n",
    "            'NumAromaticHeterocycles': rdMolDescriptors.CalcNumAromaticHeterocycles(mol),\n",
    "            'NumAliphaticHeterocycles': rdMolDescriptors.CalcNumAliphaticHeterocycles(mol),\n",
    "            'NumSaturatedHeterocycles': rdMolDescriptors.CalcNumSaturatedHeterocycles(mol),\n",
    "        }\n",
    "        descriptors_list.append(desc)\n",
    "    \n",
    "    return pd.DataFrame(descriptors_list)\n",
    "\n",
    "print(\"Computing RDKit descriptors for training data...\")\n",
    "train_rdkit = compute_rdkit_descriptors(train_df['SMILES'].values)\n",
    "print(\"Computing RDKit descriptors for test data...\")\n",
    "test_rdkit = compute_rdkit_descriptors(test_df['SMILES'].values)\n",
    "\n",
    "print(f\"\\nRDKit descriptors: {train_rdkit.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Mordred Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Mordred descriptors for training data...\n",
      "Calculating 1613 Mordred descriptors...\n",
      "c:\\Users\\tkasiror\\Desktop\\Thermophysical Property Melting Point\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\tkasiror\\Desktop\\Thermophysical Property Melting Point\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\tkasiror\\Desktop\\Thermophysical Property Melting Point\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\tkasiror\\Desktop\\Thermophysical Property Melting Point\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\tkasiror\\Desktop\\Thermophysical Property Melting Point\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\tkasiror\\Desktop\\Thermophysical Property Melting Point\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\tkasiror\\Desktop\\Thermophysical Property Melting Point\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "Valid descriptors (no NaN, non-zero variance): 897\n",
      "\n",
      "Computing Mordred descriptors for test data...\n",
      "Calculating 1613 Mordred descriptors...\n",
      "Valid descriptors (no NaN, non-zero variance): 963\n",
      "\n",
      "Final Mordred descriptors: 882\n"
     ]
    }
   ],
   "source": [
    "def compute_mordred_descriptors(smiles_list):\n",
    "    \"\"\"Compute Mordred descriptors that work for all molecules\"\"\"\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
    "    \n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    print(f\"Calculating {len(calc.descriptors)} Mordred descriptors...\")\n",
    "    df = calc.pandas(mols)\n",
    "    \n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    valid_cols = df.columns[df.notna().all()].tolist()\n",
    "    df_clean = df[valid_cols]\n",
    "    df_clean = df_clean.loc[:, df_clean.std() > 0]\n",
    "    \n",
    "    print(f\"Valid descriptors (no NaN, non-zero variance): {df_clean.shape[1]}\")\n",
    "    return df_clean\n",
    "\n",
    "print(\"Computing Mordred descriptors for training data...\")\n",
    "train_mordred = compute_mordred_descriptors(train_df['SMILES'].values)\n",
    "\n",
    "print(\"\\nComputing Mordred descriptors for test data...\")\n",
    "test_mordred = compute_mordred_descriptors(test_df['SMILES'].values)\n",
    "\n",
    "# Keep only common columns\n",
    "common_cols = list(set(train_mordred.columns) & set(test_mordred.columns))\n",
    "train_mordred = train_mordred[common_cols]\n",
    "test_mordred = test_mordred[common_cols]\n",
    "\n",
    "print(f\"\\nFinal Mordred descriptors: {len(common_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature breakdown:\n",
      "  - Original Group features: 424\n",
      "  - RDKit descriptors: 20\n",
      "  - Mordred descriptors: 882\n",
      "  - Total features: 1326\n"
     ]
    }
   ],
   "source": [
    "# Original group features\n",
    "group_cols = [col for col in train_df.columns if col.startswith('Group')]\n",
    "train_groups = train_df[group_cols]\n",
    "test_groups = test_df[group_cols]\n",
    "\n",
    "# Combine all features\n",
    "X_train = pd.concat([\n",
    "    train_groups.reset_index(drop=True),\n",
    "    train_rdkit.reset_index(drop=True),\n",
    "    train_mordred.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "X_test = pd.concat([\n",
    "    test_groups.reset_index(drop=True),\n",
    "    test_rdkit.reset_index(drop=True),\n",
    "    test_mordred.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "y_train = train_df['Tm']\n",
    "\n",
    "# Clean data\n",
    "X_train = X_train.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "X_test = X_test.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(f\"Feature breakdown:\")\n",
    "print(f\"  - Original Group features: {len(group_cols)}\")\n",
    "print(f\"  - RDKit descriptors: {train_rdkit.shape[1]}\")\n",
    "print(f\"  - Mordred descriptors: {train_mordred.shape[1]}\")\n",
    "print(f\"  - Total features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def evaluate_model(model, X, y, model_name):\n",
    "    \"\"\"Evaluate model using 5-fold cross-validation\"\"\"\n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"  {model_name}\")\n",
    "    print('='*55)\n",
    "    \n",
    "    y_pred_cv = cross_val_predict(model, X, y, cv=kfold)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "    mae = mean_absolute_error(y, y_pred_cv)\n",
    "    r2 = r2_score(y, y_pred_cv)\n",
    "    \n",
    "    print(f\"\\n  Cross-Validation Results (5-Fold):\")\n",
    "    print(f\"    RMSE: {rmse:.4f}\")\n",
    "    print(f\"    MAE:  {mae:.4f}\")\n",
    "    print(f\"    R²:   {r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\n  Training on full dataset...\")\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model, {'RMSE': rmse, 'MAE': mae, 'R2': r2}, y_pred_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  MODEL EVALUATION WITH ENHANCED FEATURES\n",
      "============================================================\n",
      "\n",
      "=======================================================\n",
      "  XGBoost\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  MODEL EVALUATION WITH ENHANCED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "xgb_trained, xgb_metrics, xgb_cv_pred = evaluate_model(xgb_model, X_train, y_train, \"XGBoost\")\n",
    "lgbm_trained, lgbm_metrics, lgbm_cv_pred = evaluate_model(lgbm_model, X_train, y_train, \"LightGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'MAE', 'R²'],\n",
    "    'XGBoost': [f\"{xgb_metrics['RMSE']:.4f}\", f\"{xgb_metrics['MAE']:.4f}\", f\"{xgb_metrics['R2']:.4f}\"],\n",
    "    'LightGBM': [f\"{lgbm_metrics['RMSE']:.4f}\", f\"{lgbm_metrics['MAE']:.4f}\", f\"{lgbm_metrics['R2']:.4f}\"]\n",
    "})\n",
    "\n",
    "def get_best(metric, xgb_val, lgbm_val):\n",
    "    if metric == 'R²':\n",
    "        return 'XGBoost' if float(xgb_val) > float(lgbm_val) else 'LightGBM'\n",
    "    return 'XGBoost' if float(xgb_val) < float(lgbm_val) else 'LightGBM'\n",
    "\n",
    "results_df['Best'] = results_df.apply(lambda r: get_best(r['Metric'], r['XGBoost'], r['LightGBM']), axis=1)\n",
    "\n",
    "print(\"\\n\" + results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, pred, name, metrics in zip(axes, [xgb_cv_pred, lgbm_cv_pred], \n",
    "                                     ['XGBoost', 'LightGBM'],\n",
    "                                     [xgb_metrics, lgbm_metrics]):\n",
    "    ax.scatter(y_train, pred, alpha=0.4, s=20, c='steelblue')\n",
    "    ax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', linewidth=2)\n",
    "    ax.set_xlabel('Actual Melting Point (K)', fontsize=12)\n",
    "    ax.set_ylabel('Predicted Melting Point (K)', fontsize=12)\n",
    "    ax.set_title(f'{name}\\nR² = {metrics[\"R2\"]:.4f}, RMSE = {metrics[\"RMSE\"]:.2f}', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('actual_vs_predicted.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: actual_vs_predicted.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_trained.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "top_30 = feature_importance.head(30)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.barh(range(len(top_30)), top_30['importance'].values, color='steelblue')\n",
    "ax.set_yticks(range(len(top_30)))\n",
    "ax.set_yticklabels(top_30['feature'].values)\n",
    "ax.set_xlabel('Feature Importance', fontsize=12)\n",
    "ax.set_title('Top 30 Features by XGBoost Importance', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: feature_importance.png\")\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions = xgb_trained.predict(X_test)\n",
    "lgbm_predictions = lgbm_trained.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "xgb_submission = pd.DataFrame({'id': test_df['id'], 'Tm': xgb_predictions})\n",
    "lgbm_submission = pd.DataFrame({'id': test_df['id'], 'Tm': lgbm_predictions})\n",
    "\n",
    "xgb_submission.to_csv('submission_xgboost_enhanced.csv', index=False)\n",
    "lgbm_submission.to_csv('submission_lightgbm_enhanced.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved:\")\n",
    "print(\"  - submission_xgboost_enhanced.csv\")\n",
    "print(\"  - submission_lightgbm_enhanced.csv\")\n",
    "\n",
    "print(f\"\\nTest predictions statistics:\")\n",
    "print(f\"  XGBoost  - Min: {xgb_predictions.min():.2f}, Max: {xgb_predictions.max():.2f}, Mean: {xgb_predictions.mean():.2f}\")\n",
    "print(f\"  LightGBM - Min: {lgbm_predictions.min():.2f}, Max: {lgbm_predictions.max():.2f}, Mean: {lgbm_predictions.mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
